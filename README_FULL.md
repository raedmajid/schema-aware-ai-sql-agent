# ðŸ§  Building AI Agents for the Enterprise - Schema-Aware AI SQL Agent
> ðŸ’¡ This project runs locally using Python, FastAPI, and Streamlit. You can connect it to any SQL-compatible database or use the built-in Northwind sample via Docker.  
> Setup typically takes **5-10 minutes** and requires **basic command-line usage**.  
> You'll configure `.env` and `config.yaml` to match your environment and optionally run a provided PostgreSQL container for fast onboarding.

## ðŸ“š Table of Contents
- [Overview](#-overview)
- [Key Features](#-key-features)
- [Real-World Use Cases](#-real-world-use-cases)
- [Modes of Operation](#-modes-of-operation)
- [Technologies Used](#-technologies-used)
- [Architecture Highlights](#-architecture-highlights)
- [Project Structure](#-project-structure)
- [Setup Instructions](#-setup-instructions)
  - [1 Prerequisites](#1-prerequisites)
  - [2 Installation](#2-installation)
  - [3 env File Setup](#3-env-file-setup)
  - [4 Config File Setup](#4-config-file-setup)
  - [5 Database Setup](#5-database-setup)
- [Running the Backend](#-running-the-backend)
- [Running the Frontend](#-running-the-frontend)
- [Accessing the Application](#-accessing-the-application)
- [Backend README](#-backend-readme)
- [Frontend README](#-frontend-readme)
- [Contributing](#-contributing)
- [Questions](#-questions)
- [License](#-license)
- [Security Considerations: Schema Exposure](#-security-considerations-schema-exposure)
- [Coming Soon / Future Enhancements](#-coming-soon--future-enhancements)

> ðŸ’¡ Tip: To preview this file locally in VS Code or editors supporting markdown content, use <kbd>Cmd</kbd>+<kbd>Shift</kbd>+<kbd>V</kbd> (or <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>V</kbd> on Windows).

---

## ðŸ” Overview

The **Schema-Aware AI SQL Agent** is a production-grade system that translates natural language into safe, executable SQL queries â€” without blindly trusting the LLM. Designed for enterprise environments, it enforces schema awareness, RBAC, RLS, and SQL sanitization to ensure compliance, correctness, and security. 

Built with open-source tools like **LangChain**, **FastAPI**, and **Streamlit**, the solution combines AI flexibility with traditional software principles to deliver a reliable, extensible, and governance-ready interface for querying structured data.

## ðŸŽ¥ Full Video Walkthrough

[![Watch the video](https://www.youtube.com/watch?v=of6CHk0Q_B0))](https://www.youtube.com/watch?v=of6CHk0Q_B0)

---

## ðŸŽ¯ Key Features

- ðŸ’¬ Natural language to SQL generation using LLMs
- ðŸ” Built-in guardrails: schema validation, RBAC, RLS, query sanitization, and prompt engineering
- ðŸš€ REST API and interactive Chat UI for flexible access
- ðŸ”„ Supports both stateless API and stateful agent modes (toggle in UI)
- ðŸ—ƒï¸ Includes sample database schema (Northwind) for testing and onboarding
- ðŸ§© Modular backend architecture designed for enterprise extensibility
- âš™ï¸ Extensible & Configurable â€“ Easily switch LLM models and database configurations
- âš¡ Real-Time Execution & Performance Optimization â€“ Designed for low-latency environments

---

## ðŸ’¼ Real-World Use Cases

- Business Intelligence Portals â€” Enable non-technical users to explore data within governed, role-restricted boundaries
- Internal Tools for Data Teams â€” Streamline analyst and operations workflows while maintaining strict access controls
- Customer Support Dashboards â€” Allow support agents to retrieve contextual data using natural language, without writing SQL
- Data Validation & Reconciliation â€” Detect anomalies, check totals, or validate consistency using conversational queries
- AI-Augmented Dev & QA â€” Assist developers and testers in understanding and debugging datasets through natural language prompts
- AI-Powered SQL Assistants â€” Support data engineering and ML workflows with secure, schema-aware SQL generation
- Secure Self-Service Data Access â€” Empower business users to generate SQL queries within defined governance and access boundaries
- Compliance-Aware Querying â€” Enforce RBAC/RLS and access rules directly in query generation for audit readiness and regulated environments
- Automated BI Workflows â€” Generate and execute SQL queries to power dashboards, reports, or scheduled pipelines
- Data Stewardship Tools â€” Help governance teams review and refine access boundaries through agent-assisted querying
- Ad Hoc Exploration for Executives â€” Let decision-makers ask structured questions without needing analysts or SQL knowledge

---

## ðŸ§  Modes of Operation

This project supports two modes of query generation:

- **API Mode (`/ask`)** â€“ Stateless, single-turn query generation.
- **AI Agent Mode (`/chat`)** â€“ Stateful, memory-aware conversations.

Switch between them using the toggle in the frontend UI.

---

## ðŸ›  Technologies Used

- **Python 3.10+**
- **FastAPI** â€“ high-performance REST backend
- **Streamlit** â€“ chat UI for natural language interaction
- **SQLAlchemy** â€“ database abstraction across SQL engines
- **LangChain** â€“ LLM orchestration and prompt flows
- **OpenAI / OpenRouter / Ollama** â€“ LLM providers
- **PostgreSQL** â€“ sample database (Northwind)
- **Docker & Docker Compose** â€“ for quick local setup

---

## ðŸ“ Architecture Highlights

Hereâ€™s a high-level look at how the system worksâ€”from UI to LLM to SQL execution.

![System Architecture](assets/System-Architecture.jpg)

*The system is composed of three main layers:*

- **Frontend (using Streamlit)** â€“ Provides an interactive UI for asking natural language questions and viewing SQL + results.
- **Backend (using FastAPI)** â€“ Hosts the API endpoints (`/ask`, `/chat`) that handle query processing, memory, LLM routing, and role enforcement.
- **Database** â€“ An SQL-compatible engine (e.g., PostgreSQL) connected via SQLAlchemy, with schema introspection and security rules applied.

This modular architecture separates AI logic, user access, and data governanceâ€”making it adaptable to enterprise needs and secure by design.

### ðŸ§  Functionality

- `/ask` â€” direct, stateless query generation
- `/chat` â€” multi-turn conversational query generation with memory
- LLM Integration â€” prompt injection protection and sanitization
- RBAC â€” table/column-level enforcement
- Schema-Aware Execution â€” validates schema, foreign keys, constraints
- Clarification Flow â€” detects vague prompts and asks follow-ups

### ðŸ” Security & Governance Model

- Enforces and simulates RBAC rules defined in `config.yaml`. These rules are hardcoded for demonstration â€” in a production system, they would be dynamically fetched from your IAM or access policy service.
- Blocks unsafe queries using SQL sanitization
- Detects hallucinations and responds gracefully
- Simulates RLS rules defined in `config.yaml`. These are demonstration rules â€” in a production system, RLS logic would typically be enforced by your database engine or a centralized policy engine.

### ðŸ› ï¸ Configuration and IAM Notes

- `config.yaml` contains role mappings and access policies
- In production, these values should be fetched from your IAM provider (e.g., Okta, Azure AD)
- `authenticate_user()` is a placeholder â€” replace with real identity checks in production

---

## ðŸ—‚ Project Structure

```
schema_Aware_AI_SQL_Agent/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agent/                # AI agent logic and memory
â”‚   â”œâ”€â”€ api/                  # FastAPI entry point and route definitions
â”‚   â”œâ”€â”€ utils/                # Configuration, logging, and utility functions
â”‚       â”œâ”€â”€config.yaml        # Access rules and system behavior
â”œâ”€â”€ database/                 # Schema parsing and SQL generation logic
â”œâ”€â”€ frontend/                 # Streamlit chat interface
â”œâ”€â”€ requirements.txt          # Project dependencies
â”œâ”€â”€ .env.example              # Sample environment variable file
â””â”€â”€ README.md                 # Main documentation
â””â”€â”€ README_FULL.md            # Full documentation
```

---

## âš™ Setup Instructions
_Follow these steps to get the system running locally. You can connect to your own database or use the provided Northwind sample._

### 1ï¸âƒ£ Prerequisites

- Python 3.10+
- Streamlit (installed via `requirements.txt`)
- SQL-compatible database (PostgreSQL, MySQL, SQL Server, etc.)
- OpenAI or local-compatible LLM provider
- Docker (optional for running the sample Northwind DB)

---

### 2ï¸âƒ£ Installation

```bash
git clone https://github.com/raedmajid/schema-aware-ai-sql-agent.git
cd schema-aware-ai-sql-agent
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

### 3ï¸âƒ£ .env File Setup

```bash
cp .env.example .env
```

Update `.env` (located in the root directory) with:

- `DATABASE_URL` â€“ your database connection string
- `OPENAI_API_KEY` â€“ if using OpenAI
- `OPENROUTER_API_KEY` â€“ if using OpenRouter
- Additional provider-specific values as needed

---

### 4ï¸âƒ£ Config File Setup

Update `backend/utils/config.yaml` to match your environment:

- `RBAC_RULES`, `RLS_RULES`, `SENSITIVE_COLUMNS`
- `LLM_PROVIDER`, model name
- `USER_SETTINGS` for simulated login identity

If you're using the Northwind sample database, no changes are required.

---


### 5ï¸âƒ£ ðŸ—„ï¸ Database Setup

You can connect to your own database or use the provided Northwind schema in PostgreSQL, with or without Docker.

To get started quickly, we recommend using the **included Dockerized PostgreSQL database with the Northwind sample schema**. It allows you to explore the system's features (RBAC, RLS, prompt engineering, SQL sanitization) with minimal setup.

Once you're comfortable, you can switch to your own database by updating your `.env` and `config.yaml` files.

---

#### ðŸ”¹ Option 1: Use Your Own Database  
_Connect to any SQL-compatible database (PostgreSQL, MySQL, SQL Server, etc.) and bring your own schema._

1. Set `DATABASE_URL` in your `.env` file.  
2. Update the following in `backend/utils/config.yaml`:
   - `RBAC_RULES`
   - `RLS_RULES`
   - `SENSITIVE_COLUMNS`

---

#### ðŸ”¹ Option 2: Use Your PostgreSQL + Northwind Sample Schema  
_Load the Northwind schema into your own PostgreSQL instance._

1. Run the database script to create the schema and seed data:

```bash
psql -U youruser -d yourdb -f database/northwind.sql
```

2. Set your `.env` file:

```env
DATABASE_URL=postgresql://youruser:yourpassword@localhost:5432/northwind
```

#### ðŸ³ Option 3: Use Docker for Prebuilt PostgreSQL, northwind database and sample data  
_Spin up a local PostgreSQL container with the Northwind schema already loaded._

If youâ€™re using this option, no manual database setup is needed.
The container will automatically create:

	â€¢	The northwind database
	â€¢	The northwind_user with password northwind_pass


1. Navigate to the `docker` folder and run:

```bash
cd docker
docker-compose up -d
```

2. Your sample `.env` file should already have this line:

```env
DATABASE_URL=postgresql://northwind_user:northwind_pass@localhost:5432/northwind
```

---

## ðŸš€ Running the Backend

```bash
uvicorn backend.api.api:app --host 127.0.0.1 --port 8000 --reload
```

> ðŸ”§ This starts the FastAPI server with live reload.

Access the interactive API docs: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ðŸ’» Running the Frontend

```bash
python3 -m streamlit run frontend/chat_UI.py
```

> ðŸ’¬ This launches the natural language UI in your browser.

---

## ðŸ–¥ Accessing the Application

Once both backend and frontend are running, visit:

[http://localhost:8501](http://localhost:8501) â€” for the Chat UI  
[http://localhost:8000/docs](http://localhost:8000/docs) â€” for interactive API access via Swagger UI  

---

### âœ… Setup Complete

If you're seeing the **Chat UI** at [http://localhost:8501](http://localhost:8501) and the **FastAPI docs** at [http://localhost:8000/docs](http://localhost:8000/docs), your system is up and running.


## ðŸ—„ Backend README

<details>
<summary><strong>Click to expand</strong></summary>

### Backend Overview

- FastAPI-powered API
- Converts natural language into secure SQL
- Supports multiple LLM providers

#### Key Components

- `api.py` â€“ FastAPI app
- `llm_client.py` â€“ LLM abstraction
- `schemaAwareSQL.py` â€“ schema validation engine
- `utils.py` â€“ auth and helper functions

#### API Endpoints

- `POST /ask` â€“ stateless SQL generation
- `POST /chat` â€“ conversational agent with memory

#### Run Locally

```bash
uvicorn backend.api.api:app --host 127.0.0.1 --port 8000 --reload
```

</details>

---

## ðŸŽ¨ Frontend README

<details>
<summary><strong>Click to expand</strong></summary>

### Frontend Overview

- Built with Streamlit
- Chat-style interface for natural language SQL
- Displays SQL and results side-by-side

#### Run Locally

```bash
python3 -m streamlit run frontend/chat_UI.py
```

#### Customization

Edit `chat_demo.py` to modify UI layout, prompt formats, or model selectors.

</details>

---

## ðŸ¤ Contributing

If you have questions, ideas, or feedback â€” open a GitHub issue or drop a comment on the YouTube walkthrough. We welcome contributions.

---

## ðŸ“¬ Questions?

Open an issue on GitHub or comment on the YouTube video linked in the repo.

---

## ðŸ“„ License

This project is licensed under the MIT License.

---

## ðŸŽ¯ Security Considerations: Schema Exposure

While this system does not share user data with LLMs, it does expose database schema metadata to generate SQL. This includes:

Table names

Column names

Relationships and keys

To mitigate schema exposure:

Option 1 â€“ Schema Filtering (Recommended)Use the config file to filter sensitive tables or columns before they are included in LLM prompts.

Option 2 â€“ Local LLMs (Best for Privacy)Run the agent using a local LLM (e.g., Ollama or LM Studio) to ensure prompts and schema never leave your environment.

---

## ðŸ§ª Coming Soon / Ideas / Potential Enhancements

Below are areas weâ€™re exploring for future iterations â€” depending on usage, feedback, and interest:

- âœ… Vector-based schema retrieval (RAG)
- âœ… Fine-tuned LLM support
- ðŸš§ OpenAPI-based schema parsing
- ðŸš§ Multi-turn clarification engine
- ðŸš§ Adaptive query optimization
- ðŸš§ Personalized query recommendations
- ðŸš§ Natural language SQL tuning (e.g., â€œmake this query fasterâ€)
- ðŸš§ Query caching and smart autocomplete
- ðŸš§ Inline data visualizations and basic analytics

---

> ðŸ’¡ Tip: To preview this file locally in VS Code or editors supporting markdown content, use <kbd>Cmd</kbd>+<kbd>Shift</kbd>+<kbd>V</kbd> (or <kbd>Ctrl</kbd>+<kbd>Shift</kbd>+<kbd>V</kbd> on Windows).